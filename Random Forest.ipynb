{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"xor\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", \"true\").csv('pitches_preprocessed.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('outs', 'pfx_x', 'pfx_z', 'pitch_num', 'px', 'pz', 'start_speed', 'sz_bot', 'sz_top', 'x0', 'y0',\n",
    " 'z0', 'batter_id', 'inning', 'p_throws', 'pitcher_id', 'stand', 'latent_pitch_type',\n",
    " 'count_status','base_status', 'binned_score_difference','latent_next_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('binned_score_difference', df.binned_score_difference +5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols =[\"latent_pitch_type\", \"pitch_num\", \"base_status\",\"binned_score_difference\",\n",
    "                                            \"count_status\"],\n",
    "                                 outputCols =[\"latent_pitch_typeH\", \"pitch_numH\", \"base_statusH\",\"binned_score_differenceH\"\n",
    "                                              ,\"count_statusH\"])\n",
    "model = encoder.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('outs','pfx_x','pfx_z','px','pz','start_speed','sz_bot','sz_top','x0',\n",
    "               'y0','z0','batter_id','inning','p_throws','pitcher_id','stand','latent_pitch_typeH','pitch_numH',\n",
    "               'base_statusH','binned_score_differenceH','count_statusH','latent_next_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+\n",
      "|label|            features|  count_statusH|binned_score_differenceH| base_statusH|    pitch_numH|latent_pitch_typeH|\n",
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+\n",
      "|  0.0|[1.0,6.08,9.83,-0...| (11,[0],[1.0])|          (10,[4],[1.0])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[0],[1.0])|\n",
      "|  0.0|[1.0,4.54,12.83,-...| (11,[2],[1.0])|          (10,[4],[1.0])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[0],[1.0])|\n",
      "|  7.0|[0.0,-3.71,9.05,-...| (11,[0],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[0],[1.0])|\n",
      "|  7.0|[0.0,4.87,-6.37,0...| (11,[2],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[7],[1.0])|\n",
      "|  0.0|[0.0,1.64,-4.12,0...| (11,[3],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[3],[1.0])|     (9,[7],[1.0])|\n",
      "|  6.0|[0.0,-2.47,9.54,-...| (11,[8],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[4],[1.0])|     (9,[0],[1.0])|\n",
      "|  6.0|[0.0,1.98,6.25,0....|(11,[10],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[5],[1.0])|     (9,[6],[1.0])|\n",
      "|  7.0|[2.0,-6.24,7.53,-...| (11,[0],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|  7.0|[2.0,2.25,-7.86,-...| (11,[1],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[7],[1.0])|\n",
      "|  3.0|[2.0,-0.03,-2.33,...| (11,[3],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[3],[1.0])|     (9,[7],[1.0])|\n",
      "|  0.0|[2.0,-7.05,6.16,-...| (11,[7],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[4],[1.0])|     (9,[2],[1.0])|\n",
      "|  2.0|[2.0,-3.57,7.96,-...| (11,[9],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[5],[1.0])|     (9,[0],[1.0])|\n",
      "|  6.0|[1.0,-6.56,5.71,0...| (11,[0],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[1],[1.0])|     (9,[3],[1.0])|\n",
      "|  6.0|[1.0,-1.15,10.16,...| (11,[1],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[2],[1.0])|     (9,[6],[1.0])|\n",
      "|  6.0|[1.0,2.3,8.94,-1....| (11,[4],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[3],[1.0])|     (9,[6],[1.0])|\n",
      "|  6.0|[1.0,-0.29,8.41,-...| (11,[6],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[4],[1.0])|     (9,[6],[1.0])|\n",
      "|  0.0|[1.0,1.36,8.65,0....| (11,[9],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[5],[1.0])|     (9,[6],[1.0])|\n",
      "|  2.0|[0.0,7.81,-6.61,0...| (11,[0],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[7],[1.0])|\n",
      "|  0.0|[0.0,-4.02,7.13,-...| (11,[2],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[3],[1.0])|\n",
      "|  0.0|[0.0,-3.36,12.2,0...| (11,[3],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(14,[3],[1.0])|     (9,[0],[1.0])|\n",
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-6]), r[-2], r[-3], r[-4], r[-5], r[-6]]).\\\n",
    "           toDF(['label','features', 'count_statusH','binned_score_differenceH','base_statusH', 'pitch_numH',\n",
    "                 'latent_pitch_typeH'])\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data= transData(df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "norm = Normalizer(inputCol='features', outputCol='features_norm', p=1.0)\n",
    "data = norm.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = ['features_norm', 'latent_pitch_typeH','pitch_numH','base_statusH',\n",
    "                                         'binned_score_differenceH','count_statusH'], outputCol = 'features_fin')\n",
    "\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select('label', 'features_fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_fin\", numTrees=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.616408\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

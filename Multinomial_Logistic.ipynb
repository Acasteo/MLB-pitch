{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"xor\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data and merge dataset on ab_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", \"true\").csv('pitches_preprocessed.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2098636"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('outs', 'pfx_x', 'pfx_z', 'pitch_num', 'px', 'pz', 'start_speed', 'sz_bot', 'sz_top', 'x0', 'y0',\n",
    " 'z0', 'batter_id', 'inning', 'p_throws', 'pitcher_id', 'stand', 'score_difference', 'latent_pitch_type',\n",
    " 'count_status','base_status', 'binned_score_difference','latent_next_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('binned_score_difference', df.binned_score_difference +5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols =[\"latent_pitch_type\", \"pitch_num\", \"base_status\",\"binned_score_difference\",\n",
    "                                            \"count_status\"],\n",
    "                                 outputCols =[\"latent_pitch_typeH\", \"pitch_numH\", \"base_statusH\",\"binned_score_differenceH\"\n",
    "                                              ,\"count_statusH\"])\n",
    "model = encoder.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('outs','pfx_x','pfx_z','px','pz','start_speed','sz_bot','sz_top','x0',\n",
    "               'y0','z0','batter_id','inning','p_throws','pitcher_id','stand','latent_pitch_typeH','pitch_numH',\n",
    "               'base_statusH','binned_score_differenceH','count_statusH','latent_next_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def weight(pitch):\n",
    "    if  pitch == 0.0: return 1.0/0.36\n",
    "    elif pitch == 1.0: return 1.0/0.17\n",
    "    elif pitch == 2.0: return 1.0/0.12\n",
    "    elif pitch == 3.0: return 1.0/0.1\n",
    "    elif pitch == 4.0: return 1.0/0.08\n",
    "    elif pitch == 5.0: return 1.0/0.08\n",
    "    elif pitch == 6.0: return 1.0/0.05\n",
    "    elif pitch == 7.0: return 1.0/0.02\n",
    "    elif pitch == 8.0: return 1.0/0.01\n",
    "    elif pitch == 9.0: return 1.0/0.01\n",
    "    elif pitch == 10.0: return 1.0/0.01\n",
    "    \n",
    "udfweight = udf(weight, DoubleType())\n",
    "df = df.withColumn(\"weights\", udfweight('latent_next_pitch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+------------------+-----------+------+------+-------------------+----+------------------+---------+------+--------+----------+-----+------------------+--------------+-------------+------------------------+---------------+-----------------+------------------+\n",
      "|outs|pfx_x|pfx_z|                  px|                pz|start_speed|sz_bot|sz_top|                 x0|  y0|                z0|batter_id|inning|p_throws|pitcher_id|stand|latent_pitch_typeH|    pitch_numH| base_statusH|binned_score_differenceH|  count_statusH|latent_next_pitch|           weights|\n",
      "+----+-----+-----+--------------------+------------------+-----------+------+------+-------------------+----+------------------+---------+------+--------+----------+-----+------------------+--------------+-------------+------------------------+---------------+-----------------+------------------+\n",
      "| 1.0| 6.08| 9.83|              -0.532|             2.702|       93.7|  1.86|  3.83|              2.161|50.0|             6.151|   120074|     1|       0|    430935|    0|     (9,[0],[1.0])|(14,[1],[1.0])|(7,[0],[1.0])|          (10,[4],[1.0])| (11,[0],[1.0])|              0.0|2.7777777777777777|\n",
      "| 1.0| 4.54|12.83|              -0.312|             2.224|       93.2|  1.92|  3.75|              2.316|50.0|5.9239999999999995|   120074|     1|       0|    430935|    0|     (9,[0],[1.0])|(14,[2],[1.0])|(7,[0],[1.0])|          (10,[4],[1.0])| (11,[2],[1.0])|              0.0|2.7777777777777777|\n",
      "| 0.0|-3.71| 9.05|-0.05900000000000...|2.6319999999999997|       91.3|  1.74|  3.51|             -2.316|50.0|              6.18|   543216|     8|       1|    451584|    0|     (9,[0],[1.0])|(14,[1],[1.0])|(7,[0],[1.0])|              (10,[],[])| (11,[0],[1.0])|              7.0|              50.0|\n",
      "| 0.0| 4.87|-6.37|               0.794|             1.785|       81.6|  1.66|  3.47|             -2.335|50.0|             6.149|   543216|     8|       1|    451584|    0|     (9,[7],[1.0])|(14,[2],[1.0])|(7,[0],[1.0])|              (10,[],[])| (11,[2],[1.0])|              7.0|              50.0|\n",
      "| 0.0| 1.64|-4.12|                0.13|             1.604|       83.2|  1.66|  3.51|             -2.208|50.0|             6.269|   543216|     8|       1|    451584|    0|     (9,[7],[1.0])|(14,[3],[1.0])|(7,[0],[1.0])|              (10,[],[])| (11,[3],[1.0])|              0.0|2.7777777777777777|\n",
      "| 0.0|-2.47| 9.54| -0.9309999999999999|              1.17|       94.0|  1.66|  3.39|             -2.274|50.0|              6.12|   543216|     8|       1|    451584|    0|     (9,[0],[1.0])|(14,[4],[1.0])|(7,[0],[1.0])|              (10,[],[])| (11,[8],[1.0])|              6.0|              20.0|\n",
      "| 0.0| 1.98| 6.25|               0.871|             1.564|       91.3|  1.66|   3.4|             -2.385|50.0| 6.117999999999999|   543216|     8|       1|    451584|    0|     (9,[6],[1.0])|(14,[5],[1.0])|(7,[0],[1.0])|              (10,[],[])|(11,[10],[1.0])|              6.0|              20.0|\n",
      "| 2.0|-6.24| 7.53|              -1.649|             1.135|       92.7|  1.55|  3.41|             -1.805|50.0|              5.64|   592626|     2|       1|    448306|    0|     (9,[2],[1.0])|(14,[1],[1.0])|(7,[0],[1.0])|          (10,[6],[1.0])| (11,[0],[1.0])|              7.0|              50.0|\n",
      "| 2.0| 2.25|-7.86|              -0.015|             0.972|       79.5|  1.55|  3.41|              -1.92|50.0|             5.896|   592626|     2|       1|    448306|    0|     (9,[7],[1.0])|(14,[2],[1.0])|(7,[0],[1.0])|          (10,[6],[1.0])| (11,[1],[1.0])|              7.0|              50.0|\n",
      "| 2.0|-0.03|-2.33|  1.4340000000000002|            -1.358|       81.6|  1.68|  3.49|              -1.78|50.0|             5.678|   592626|     2|       1|    448306|    0|     (9,[7],[1.0])|(14,[3],[1.0])|(7,[0],[1.0])|          (10,[6],[1.0])| (11,[3],[1.0])|              3.0|              10.0|\n",
      "| 2.0|-7.05| 6.16| -1.7690000000000001|1.5919999999999999|       93.2|  1.64|  3.49|-1.8259999999999998|50.0|             5.631|   592626|     2|       1|    448306|    0|     (9,[2],[1.0])|(14,[4],[1.0])|(7,[0],[1.0])|          (10,[6],[1.0])| (11,[7],[1.0])|              0.0|2.7777777777777777|\n",
      "| 2.0|-3.57| 7.96| -0.5870000000000001|             3.285|       93.3|  1.55|  3.41|             -1.489|50.0| 5.712999999999999|   592626|     2|       1|    448306|    0|     (9,[0],[1.0])|(14,[5],[1.0])|(7,[0],[1.0])|          (10,[6],[1.0])| (11,[9],[1.0])|              2.0| 8.333333333333334|\n",
      "| 1.0|-6.56| 5.71|               0.503|            -0.504|       81.8|  1.66|  3.39|             -1.224|50.0|             5.671|   477195|     5|       1|    542914|    0|     (9,[3],[1.0])|(14,[1],[1.0])|(7,[4],[1.0])|          (10,[1],[1.0])| (11,[0],[1.0])|              6.0|              20.0|\n",
      "| 1.0|-1.15|10.16|              -1.466|1.8869999999999998|       92.0|  1.66|  3.35|-1.3769999999999998|50.0|             5.843|   477195|     5|       1|    542914|    0|     (9,[6],[1.0])|(14,[2],[1.0])|(7,[4],[1.0])|          (10,[1],[1.0])| (11,[1],[1.0])|              6.0|              20.0|\n",
      "| 1.0|  2.3| 8.94| -1.3359999999999999|3.1630000000000003|       91.9|  1.72|  3.51|-1.3419999999999999|50.0|             5.959|   477195|     5|       1|    542914|    0|     (9,[6],[1.0])|(14,[3],[1.0])|(7,[4],[1.0])|          (10,[1],[1.0])| (11,[4],[1.0])|              6.0|              20.0|\n",
      "| 1.0|-0.29| 8.41|               -0.45|3.2739999999999996|       92.1|  1.66|  3.42|             -1.348|50.0|             5.903|   477195|     5|       1|    542914|    0|     (9,[6],[1.0])|(14,[4],[1.0])|(7,[4],[1.0])|          (10,[1],[1.0])| (11,[6],[1.0])|              6.0|              20.0|\n",
      "| 1.0| 1.36| 8.65| 0.47600000000000003|             2.465|       90.7|  1.66|  3.55|              -1.15|50.0|5.9079999999999995|   477195|     5|       1|    542914|    0|     (9,[6],[1.0])|(14,[5],[1.0])|(7,[4],[1.0])|          (10,[1],[1.0])| (11,[9],[1.0])|              0.0|2.7777777777777777|\n",
      "| 0.0| 7.81|-6.61| 0.47700000000000004|             1.786|       80.6|  1.36|  3.49|             -1.621|50.0|             6.126|   456665|     5|       1|    501992|    1|     (9,[7],[1.0])|(14,[1],[1.0])|(7,[0],[1.0])|          (10,[2],[1.0])| (11,[0],[1.0])|              2.0| 8.333333333333334|\n",
      "| 0.0|-4.02| 7.13|              -0.188|              0.56|       86.2|  1.43|  3.44|              -1.57|50.0|5.8020000000000005|   456665|     5|       1|    501992|    1|     (9,[3],[1.0])|(14,[2],[1.0])|(7,[0],[1.0])|          (10,[2],[1.0])| (11,[2],[1.0])|              0.0|2.7777777777777777|\n",
      "| 0.0|-3.36| 12.2|               0.165|1.7530000000000001|       93.9|  1.53|  3.61|-1.6680000000000001|50.0| 5.888999999999999|   456665|     5|       1|    501992|    1|     (9,[0],[1.0])|(14,[3],[1.0])|(7,[0],[1.0])|          (10,[2],[1.0])| (11,[3],[1.0])|              0.0|2.7777777777777777|\n",
      "+----+-----+-----+--------------------+------------------+-----------+------+------+-------------------+----+------------------+---------+------+--------+----------+-----+------------------+--------------+-------------+------------------------+---------------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+------------------+\n",
      "|label|            features|  count_statusH|binned_score_differenceH| base_statusH|    pitch_numH|latent_pitch_typeH|           weights|\n",
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+------------------+\n",
      "|  0.0|[1.0,6.08,9.83,-0...| (11,[2],[1.0])|          (10,[4],[1.0])|(7,[0],[1.0])|(15,[2],[1.0])|     (9,[0],[1.0])|2.7777777777777777|\n",
      "|  0.0|[1.0,4.54,12.83,-...| (11,[5],[1.0])|          (10,[4],[1.0])|(7,[0],[1.0])|(15,[3],[1.0])|     (9,[0],[1.0])|2.7777777777777777|\n",
      "|  7.0|[0.0,-3.71,9.05,-...| (11,[2],[1.0])|              (10,[],[])|(7,[0],[1.0])|(15,[2],[1.0])|     (9,[0],[1.0])|              50.0|\n",
      "|  7.0|[0.0,4.87,-6.37,0...| (11,[3],[1.0])|              (10,[],[])|(7,[0],[1.0])|(15,[3],[1.0])|     (9,[7],[1.0])|              50.0|\n",
      "|  0.0|[0.0,1.64,-4.12,0...| (11,[8],[1.0])|              (10,[],[])|(7,[0],[1.0])|(15,[4],[1.0])|     (9,[7],[1.0])|2.7777777777777777|\n",
      "|  6.0|[0.0,-2.47,9.54,-...|(11,[10],[1.0])|              (10,[],[])|(7,[0],[1.0])|(15,[5],[1.0])|     (9,[0],[1.0])|              20.0|\n",
      "|  6.0|[0.0,1.98,6.25,0....|     (11,[],[])|              (10,[],[])|(7,[0],[1.0])|(15,[6],[1.0])|     (9,[6],[1.0])|              20.0|\n",
      "|  7.0|[2.0,-6.24,7.53,-...| (11,[1],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(15,[2],[1.0])|     (9,[2],[1.0])|              50.0|\n",
      "|  7.0|[2.0,2.25,-7.86,-...| (11,[3],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(15,[3],[1.0])|     (9,[7],[1.0])|              50.0|\n",
      "|  3.0|[2.0,-0.03,-2.33,...| (11,[7],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(15,[4],[1.0])|     (9,[7],[1.0])|              10.0|\n",
      "|  0.0|[2.0,-7.05,6.16,-...| (11,[9],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(15,[5],[1.0])|     (9,[2],[1.0])|2.7777777777777777|\n",
      "|  2.0|[2.0,-3.57,7.96,-...|     (11,[],[])|          (10,[6],[1.0])|(7,[0],[1.0])|(15,[6],[1.0])|     (9,[0],[1.0])| 8.333333333333334|\n",
      "|  6.0|[1.0,-6.56,5.71,0...| (11,[1],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(15,[2],[1.0])|     (9,[3],[1.0])|              20.0|\n",
      "|  6.0|[1.0,-1.15,10.16,...| (11,[4],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(15,[3],[1.0])|     (9,[6],[1.0])|              20.0|\n",
      "|  6.0|[1.0,2.3,8.94,-1....| (11,[6],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(15,[4],[1.0])|     (9,[6],[1.0])|              20.0|\n",
      "|  6.0|[1.0,-0.29,8.41,-...| (11,[9],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(15,[5],[1.0])|     (9,[6],[1.0])|              20.0|\n",
      "|  0.0|[1.0,1.36,8.65,0....|     (11,[],[])|          (10,[1],[1.0])|(7,[4],[1.0])|(15,[6],[1.0])|     (9,[6],[1.0])|2.7777777777777777|\n",
      "|  2.0|[0.0,7.81,-6.61,0...| (11,[2],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(15,[2],[1.0])|     (9,[7],[1.0])| 8.333333333333334|\n",
      "|  0.0|[0.0,-4.02,7.13,-...| (11,[3],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(15,[3],[1.0])|     (9,[3],[1.0])|2.7777777777777777|\n",
      "|  0.0|[0.0,-3.36,12.2,0...| (11,[8],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(15,[4],[1.0])|     (9,[0],[1.0])|2.7777777777777777|\n",
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[-2], Vectors.dense(r[:-7]), r[-3], r[-4], r[-5], r[-6], r[-7], r[-1]]).\\\n",
    "           toDF(['label','features', 'count_statusH','binned_score_differenceH','base_statusH', 'pitch_numH',\n",
    "                 'latent_pitch_typeH', 'weights'])\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data= transData(df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "norm = Normalizer(inputCol='features', outputCol='features_norm', p=1.0)\n",
    "data = norm.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = ['features_norm', 'latent_pitch_typeH','pitch_numH','base_statusH',\n",
    "                                         'binned_score_differenceH','count_statusH'], outputCol = 'features_fin')\n",
    "\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj = df.filter(df['latent_next_pitch']==0.0)\n",
    "minor = df.filter(df['latent_next_pitch']!=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "\n",
    "maj_split = maj.randomSplit([0.3, 0.7], 1234)\n",
    "minor_split = minor.randomSplit([0.8, 0.2], 1234)\n",
    "maj_train = maj_split[0]\n",
    "maj_test = maj_split[1]\n",
    "minor_train = minor_split[0]\n",
    "minor_test = minor_split[1]\n",
    "\n",
    "train_trial = maj_train.union(minor_train)\n",
    "test_trial = maj_test.union(minor_test)\n",
    "\n",
    "train_trial = train_trial.orderBy(rand())\n",
    "test_trial = test_trial.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-32b6cf2f4549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_trial' is not defined"
     ]
    }
   ],
   "source": [
    "train_trial = transData(train_trial)\n",
    "test_trial = transData(test_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "df = transData(df)\n",
    "pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features_fin\", maxIter=100, regParam=0.01,\n",
    "                        elasticNetParam=1.0, family=\"multinomial\", weightCol = 'weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(outs=1.0, pfx_x=6.08, pfx_z=9.83, px=-0.532, pz=2.702, start_speed=93.7, sz_bot=1.86, sz_top=3.83, x0=2.161, y0=50.0, z0=6.151, batter_id=120074, inning=1, p_throws=0, pitcher_id=430935, stand=0, latent_pitch_typeH=SparseVector(9, {0: 1.0}), pitch_numH=SparseVector(15, {2: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), binned_score_differenceH=SparseVector(10, {4: 1.0}), count_statusH=SparseVector(11, {2: 1.0}), latent_next_pitch=0.0, weights=2.7777777777777777)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=DenseVector([0.0, -15.78, 5.94, -2.249, 2.089, 82.8, 1.66, 3.54, -1.975, 50.0, 6.783, 457454.0, 7.0, 1.0, 607352.0, 0.0]), count_statusH=SparseVector(11, {1: 1.0}), binned_score_differenceH=SparseVector(10, {4: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), pitch_numH=SparseVector(15, {2: 1.0}), latent_pitch_typeH=SparseVector(9, {3: 1.0}), weights=2.7777777777777777, features_norm=DenseVector([0.0, -0.0, 0.0, -0.0, 0.0, 0.0001, 0.0, 0.0, -0.0, 0.0, 0.0, 0.4295, 0.0, 0.0, 0.5703, 0.0]), features_fin=SparseVector(68, {1: -0.0, 2: 0.0, 3: -0.0, 4: 0.0, 5: 0.0001, 6: 0.0, 7: 0.0, 8: -0.0, 9: 0.0, 10: 0.0, 11: 0.4295, 12: 0.0, 13: 0.0, 14: 0.5703, 19: 1.0, 27: 1.0, 40: 1.0, 51: 1.0, 58: 1.0}))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the coefficients and intercept for multinomial logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the objective per iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate by label:\n",
      "label 0: 0.07194978499504585\n",
      "label 1: 0.12156024147363957\n",
      "label 2: 0.08153455956238347\n",
      "label 3: 0.07885883798666518\n",
      "label 4: 0.04329297101392945\n",
      "label 5: 0.07105590512191881\n",
      "label 6: 0.03688869267144639\n",
      "label 7: 0.017252252837990714\n",
      "label 8: 0.27249991111226035\n",
      "label 9: 0.009252093855076299\n"
     ]
    }
   ],
   "source": [
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate by label:\n",
      "label 0: 0.14901141660965558\n",
      "label 1: 0.32804408508999905\n",
      "label 2: 0.2306238846705623\n",
      "label 3: 0.38692985952326014\n",
      "label 4: 0.5388199673633093\n",
      "label 5: 0.2380154574918973\n",
      "label 6: 0.31501314880926146\n",
      "label 7: 0.29389483833201335\n",
      "label 8: 0.6040140172029309\n",
      "label 9: 0.6639275179098187\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision by label:\n",
      "label 0: 0.5264886568962056\n",
      "label 1: 0.3477477845178999\n",
      "label 2: 0.26577470240975515\n",
      "label 3: 0.3859394615706514\n",
      "label 4: 0.5223424024396055\n",
      "label 5: 0.22466019051922137\n",
      "label 6: 0.32789943724002935\n",
      "label 7: 0.2867654470315492\n",
      "label 8: 0.03786644602633418\n",
      "label 9: 0.21348238482384824\n",
      "Recall by label:\n",
      "label 0: 0.14901141660965558\n",
      "label 1: 0.32804408508999905\n",
      "label 2: 0.2306238846705623\n",
      "label 3: 0.38692985952326014\n",
      "label 4: 0.5388199673633093\n",
      "label 5: 0.2380154574918973\n",
      "label 6: 0.31501314880926146\n",
      "label 7: 0.29389483833201335\n",
      "label 8: 0.6040140172029309\n",
      "label 9: 0.6639275179098187\n",
      "F-measure by label:\n",
      "label 0: 0.23228071667215827\n",
      "label 1: 0.3376086897299814\n",
      "label 2: 0.24695474931713693\n",
      "label 3: 0.38643402597130516\n",
      "label 4: 0.530453254363426\n",
      "label 5: 0.2311450721753321\n",
      "label 6: 0.3213271491619149\n",
      "label 7: 0.29028637507652544\n",
      "label 8: 0.07126518251232321\n",
      "label 9: 0.3230800779247411\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2755816049207258\n",
      "FPR: 0.07972685555108189\n",
      "TPR: 0.2755816049207258\n",
      "F-measure: 0.2965007673905309\n",
      "Precision: 0.4011340963039981\n",
      "Recall: 0.2755816049207258\n"
     ]
    }
   ],
   "source": [
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27522829730666976"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "predictions = lrModel.transform(test)\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data accuracy with weights 0.27522829730666976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSummary = predictions.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-d9480c827588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfalsePositiveRate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedFalsePositiveRate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtruePositiveRate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedTruePositiveRate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfMeasure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedFMeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedPrecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'accuracy'"
     ]
    }
   ],
   "source": [
    "accuracy = testSummary.accuracy\n",
    "falsePositiveRate = testSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = testSummary.weightedTruePositiveRate\n",
    "fMeasure = testSummary.weightedFMeasure()\n",
    "precision = testSummary.weightedPrecision\n",
    "recall = testSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  8.0| 17414|\n",
      "|  0.0|406407|\n",
      "|  7.0| 26761|\n",
      "|  1.0|179941|\n",
      "|  4.0| 96871|\n",
      "|  3.0|117153|\n",
      "|  2.0|134783|\n",
      "| 10.0|   593|\n",
      "|  6.0| 59836|\n",
      "|  5.0| 93880|\n",
      "|  9.0|  4589|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138228"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ['outs', 'pfx_x', 'pfx_z', 'pitch_num', 'px', 'pz', 'start_speed',\n",
    "        'sz_bot', 'sz_top', 'x0', 'y0','z0', 'inning', 'p_throws', 'stand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "                            inputCols=[c for c in df.columns if c in pred],\n",
    "                            outputCol='features').setHandleInvalid('skip')\n",
    "output = assembler.transform(df)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scaleroutput = scaler.fit(output)\n",
    "scaledoutput = scaleroutput.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=5, inputCol=\"scaledFeatures\", outputCol=\"pcaFeatures\")\n",
    "PC = pca.fit(scaledoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledoutput = PC.transform(scaledoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(outs=1.0, pfx_x=6.08, pfx_z=9.83, px=-0.532, pz=2.702, start_speed=93.7, sz_bot=1.86, sz_top=3.83, x0=2.161, y0=50.0, z0=6.151, batter_id=120074, inning=1, p_throws=0, pitcher_id=430935, stand=0, latent_pitch_typeH=SparseVector(9, {0: 1.0}), pitch_numH=SparseVector(15, {2: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), binned_score_differenceH=SparseVector(10, {4: 1.0}), count_statusH=SparseVector(11, {2: 1.0}), latent_next_pitch=0.0, weights=2.7777777777777777, features=DenseVector([1.0, 6.08, 9.83, -0.532, 2.702, 93.7, 1.86, 3.83, 2.161, 50.0, 6.151, 1.0, 0.0, 0.0]), scaledFeatures=DenseVector([0.0229, 1.1514, 0.9067, -0.5944, 0.4667, 0.8868, 1.8927, 1.7975, 1.6667, 0.0, 0.7376, -1.4967, -1.6522, -1.1755]), pcaFeatures=DenseVector([-1.7737, -2.8571, -1.4434, -1.8198, -0.413]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledoutput.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"latent_next_pitch\", featuresCol=\"pcaFeatures\", maxIter=100, regParam=0.01,\n",
    "                        elasticNetParam=1.0, family=\"multinomial\", weightCol = 'weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = scaledoutput.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the objective per iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate by label:\n",
      "label 0: 6.216229722597702e-05\n",
      "label 1: 0.0017388655972056324\n",
      "label 2: 0.0\n",
      "label 3: 0.04792352012352567\n",
      "label 4: 0.09028928599494468\n",
      "label 5: 0.0\n",
      "label 6: 0.0\n",
      "label 7: 0.055790028908898365\n",
      "label 8: 0.7749497699033222\n",
      "label 9: 0.01864751517895143\n"
     ]
    }
   ],
   "source": [
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate by label:\n",
      "label 0: 7.971648263547247e-05\n",
      "label 1: 0.002375433420815693\n",
      "label 2: 0.0\n",
      "label 3: 0.05381225517627308\n",
      "label 4: 0.1849064039408867\n",
      "label 5: 0.0\n",
      "label 6: 0.0\n",
      "label 7: 0.06360071546505229\n",
      "label 8: 0.882928368570527\n",
      "label 9: 0.04800667919014819\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision by label:\n",
      "label 0: 0.4069767441860465\n",
      "label 1: 0.21351700387430048\n",
      "label 2: 0.0\n",
      "label 3: 0.1257005604483587\n",
      "label 4: 0.15218695772043916\n",
      "label 5: 0.0\n",
      "label 6: 0.0\n",
      "label 7: 0.02622918262547167\n",
      "label 8: 0.020017660838317478\n",
      "label 9: 0.009734625640157446\n",
      "Recall by label:\n",
      "label 0: 7.971648263547247e-05\n",
      "label 1: 0.002375433420815693\n",
      "label 2: 0.0\n",
      "label 3: 0.05381225517627308\n",
      "label 4: 0.1849064039408867\n",
      "label 5: 0.0\n",
      "label 6: 0.0\n",
      "label 7: 0.06360071546505229\n",
      "label 8: 0.882928368570527\n",
      "label 9: 0.04800667919014819\n",
      "F-measure by label:\n",
      "label 0: 0.00015940174248876216\n",
      "label 1: 0.00469859373741871\n",
      "label 2: 0.0\n",
      "label 3: 0.07536209168254465\n",
      "label 4: 0.16695874958856338\n",
      "label 5: 0.0\n",
      "label 6: 0.0\n",
      "label 7: 0.037141192776650664\n",
      "label 8: 0.039147767531897755\n",
      "label 9: 0.01618692378070237\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03863233422443547\n",
      "FPR: 0.028033482228509442\n",
      "TPR: 0.03863233422443547\n",
      "F-measure: 0.024451888348187328\n",
      "Precision: 0.20479665909090616\n",
      "Recall: 0.03863233422443547\n"
     ]
    }
   ],
   "source": [
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With PCA and Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpca = LogisticRegression(labelCol=\"label\", featuresCol=\"pcaFeatures\",\n",
    "                        family=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lrpca.regParam, [0.1, 0.01]).addGrid(lrpca.elasticNetParam, [0, 1]).addGrid(lrpca.maxIter, [1, 5, 10]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(\n",
    "    estimator=lrpca,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModelpca = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionspca = lrModelpca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracypca = evaluatortwo.evaluate(predictionspca)\n",
    "print(\"Accuracy = %g\" % (accuracypca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisionpca = evaluatorthree.evaluate(predictionspca)\n",
    "print(\"Weighted Precision = %g\" % precisionpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recallpca = evaluatorfour.evaluate(predictionspca)\n",
    "print(\"Weighted Recall = %g\" % recallpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1pca = evaluator.evaluate(predictionspca)\n",
    "print(\"F1 = %g\" % f1pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

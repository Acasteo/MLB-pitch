{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"xor\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data and merge dataset on ab_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", \"true\").csv('pitches_preprocessed.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('outs', 'double'),\n",
       " ('pfx_x', 'double'),\n",
       " ('pfx_z', 'double'),\n",
       " ('pitch_num', 'double'),\n",
       " ('px', 'double'),\n",
       " ('pz', 'double'),\n",
       " ('start_speed', 'double'),\n",
       " ('sz_bot', 'double'),\n",
       " ('sz_top', 'double'),\n",
       " ('x0', 'double'),\n",
       " ('y0', 'double'),\n",
       " ('z0', 'double'),\n",
       " ('batter_id', 'int'),\n",
       " ('inning', 'int'),\n",
       " ('p_throws', 'int'),\n",
       " ('pitcher_id', 'int'),\n",
       " ('stand', 'int'),\n",
       " ('top', 'int'),\n",
       " ('score_difference', 'double'),\n",
       " ('latent_pitch_type', 'double'),\n",
       " ('latent_next_pitch', 'double'),\n",
       " ('count_status', 'int'),\n",
       " ('base_status', 'int'),\n",
       " ('binned_score_difference', 'int')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 1, 3, -5, 5, 4, -4, -2, 2, -3, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('binned_score_difference').distinct().rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(subset=[\"count_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------+\n",
      "|binned_score_difference| count|\n",
      "+-----------------------+------+\n",
      "|                     -1|251268|\n",
      "|                      1|255069|\n",
      "|                      3|119318|\n",
      "|                     -5|143507|\n",
      "|                      5|150485|\n",
      "|                      4| 83214|\n",
      "|                     -4| 78692|\n",
      "|                     -2|171465|\n",
      "|                      2|177304|\n",
      "|                     -3|113469|\n",
      "|                      0|562198|\n",
      "+-----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('binned_score_difference').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|latent_pitch_type| count|\n",
      "+-----------------+------+\n",
      "|              8.0| 30932|\n",
      "|              0.0|763599|\n",
      "|              7.0| 50315|\n",
      "|              1.0|330376|\n",
      "|              4.0|178452|\n",
      "|              3.0|211755|\n",
      "|              2.0|244465|\n",
      "|             10.0|  1165|\n",
      "|              6.0|109587|\n",
      "|              5.0|177058|\n",
      "|              9.0|  8285|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('latent_pitch_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|latent_next_pitch| count|\n",
      "+-----------------+------+\n",
      "|              8.0| 30932|\n",
      "|              0.0|763599|\n",
      "|              7.0| 50315|\n",
      "|              1.0|330376|\n",
      "|              4.0|178452|\n",
      "|              3.0|211755|\n",
      "|              2.0|244465|\n",
      "|             10.0|  1165|\n",
      "|              6.0|109587|\n",
      "|              5.0|177058|\n",
      "|              9.0|  8285|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('latent_next_pitch').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'outs',\n",
       " 'pfx_x',\n",
       " 'pfx_z',\n",
       " 'pitch_num',\n",
       " 'px',\n",
       " 'pz',\n",
       " 'start_speed',\n",
       " 'sz_bot',\n",
       " 'sz_top',\n",
       " 'x0',\n",
       " 'y0',\n",
       " 'z0',\n",
       " 'batter_id',\n",
       " 'inning',\n",
       " 'p_throws',\n",
       " 'pitcher_id',\n",
       " 'stand',\n",
       " 'top',\n",
       " 'score_difference',\n",
       " 'latent_pitch_type',\n",
       " 'latent_next_pitch',\n",
       " 'count_status',\n",
       " 'base_status',\n",
       " 'binned_score_difference']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('outs', 'pfx_x', 'pfx_z', 'pitch_num', 'px', 'pz', 'start_speed', 'sz_bot', 'sz_top', 'x0', 'y0',\n",
    " 'z0', 'batter_id', 'inning', 'p_throws', 'pitcher_id', 'stand', 'top', 'score_difference', 'latent_pitch_type',\n",
    " 'count_status','base_status', 'binned_score_difference','latent_next_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outs',\n",
       " 'pfx_x',\n",
       " 'pfx_z',\n",
       " 'pitch_num',\n",
       " 'px',\n",
       " 'pz',\n",
       " 'start_speed',\n",
       " 'sz_bot',\n",
       " 'sz_top',\n",
       " 'x0',\n",
       " 'y0',\n",
       " 'z0',\n",
       " 'batter_id',\n",
       " 'inning',\n",
       " 'p_throws',\n",
       " 'pitcher_id',\n",
       " 'stand',\n",
       " 'top',\n",
       " 'score_difference',\n",
       " 'latent_pitch_type',\n",
       " 'count_status',\n",
       " 'base_status',\n",
       " 'binned_score_difference',\n",
       " 'latent_next_pitch']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[1.0,6.08,9.83,1....|\n",
      "|  0.0|[1.0,4.54,12.83,2...|\n",
      "|  0.0|[0.0,-3.71,9.05,1...|\n",
      "|  7.0|[0.0,4.87,-6.37,2...|\n",
      "|  7.0|[0.0,1.64,-4.12,3...|\n",
      "|  0.0|[0.0,-2.47,9.54,4...|\n",
      "|  6.0|[0.0,1.98,6.25,5....|\n",
      "|  2.0|[2.0,-6.24,7.53,1...|\n",
      "|  7.0|[2.0,2.25,-7.86,2...|\n",
      "|  7.0|[2.0,-0.03,-2.33,...|\n",
      "|  2.0|[2.0,-7.05,6.16,4...|\n",
      "|  0.0|[2.0,-3.57,7.96,5...|\n",
      "|  3.0|[1.0,-6.56,5.71,1...|\n",
      "|  6.0|[1.0,-1.15,10.16,...|\n",
      "|  6.0|[1.0,2.3,8.94,3.0...|\n",
      "|  6.0|[1.0,-0.29,8.41,4...|\n",
      "|  6.0|[1.0,1.36,8.65,5....|\n",
      "|  7.0|[0.0,7.81,-6.61,1...|\n",
      "|  3.0|[0.0,-4.02,7.13,2...|\n",
      "|  0.0|[0.0,-3.36,12.2,3...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).\\\n",
    "           toDF(['label','features'])\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data= transData(df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify layers for the neural network: input layer of size 11 (features), two intermediate of size 5 and 4 and output of size 7 (classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currently not working so experimenting with other code\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "layers = [11, 5, 4, 4, 3 , 11]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "FNN = MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\\\n",
    "                                         maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "# Chain indexers and forest in a Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, FNN, labelConverter])\n",
    "# train the model\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "layers = [23, 20, 15, 11]\n",
    "\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.3631949095780308\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With layers = [23, 20, 15, 6, 11] accuracy = 0.36312009234584086\n",
    "\n",
    "With layers = [23, 20, 15, 11] accuracy = 0.3631949095780308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

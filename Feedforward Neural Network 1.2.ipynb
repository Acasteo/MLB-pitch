{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"xor\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data and merge dataset on ab_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", \"true\").csv('pitches_preprocessed.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712127"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|latent_next_pitch|latent_pitch_type|\n",
      "+-----------------+-----------------+\n",
      "|              0.0|              0.0|\n",
      "|              0.0|              0.0|\n",
      "|              7.0|              0.0|\n",
      "|              7.0|              7.0|\n",
      "|              0.0|              7.0|\n",
      "|              6.0|              0.0|\n",
      "|              6.0|              6.0|\n",
      "|              7.0|              2.0|\n",
      "|              7.0|              7.0|\n",
      "|              3.0|              7.0|\n",
      "|              0.0|              2.0|\n",
      "|              2.0|              0.0|\n",
      "|              6.0|              3.0|\n",
      "|              6.0|              6.0|\n",
      "|              6.0|              6.0|\n",
      "|              6.0|              6.0|\n",
      "|              0.0|              6.0|\n",
      "|              2.0|              7.0|\n",
      "|              0.0|              3.0|\n",
      "|              0.0|              0.0|\n",
      "+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('latent_next_pitch', 'latent_pitch_type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('outs', 'double'),\n",
       " ('pfx_x', 'double'),\n",
       " ('pfx_z', 'double'),\n",
       " ('pitch_num', 'double'),\n",
       " ('px', 'double'),\n",
       " ('pz', 'double'),\n",
       " ('start_speed', 'double'),\n",
       " ('sz_bot', 'double'),\n",
       " ('sz_top', 'double'),\n",
       " ('x0', 'double'),\n",
       " ('y0', 'double'),\n",
       " ('z0', 'double'),\n",
       " ('batter_id', 'int'),\n",
       " ('inning', 'int'),\n",
       " ('p_throws', 'int'),\n",
       " ('pitcher_id', 'int'),\n",
       " ('stand', 'int'),\n",
       " ('top', 'int'),\n",
       " ('score_difference', 'double'),\n",
       " ('latent_pitch_type', 'double'),\n",
       " ('latent_next_pitch', 'double'),\n",
       " ('count_status', 'int'),\n",
       " ('base_status', 'int'),\n",
       " ('binned_score_difference', 'int')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 1, 3, -5, 5, 4, -4, -2, 2, -3, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('binned_score_difference').distinct().rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(subset=[\"count_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------+\n",
      "|binned_score_difference| count|\n",
      "+-----------------------+------+\n",
      "|                     -1|203766|\n",
      "|                      1|206991|\n",
      "|                      3| 97133|\n",
      "|                     -5|116771|\n",
      "|                      5|122646|\n",
      "|                      4| 67897|\n",
      "|                     -4| 63988|\n",
      "|                     -2|139310|\n",
      "|                      2|144543|\n",
      "|                     -3| 91749|\n",
      "|                      0|457333|\n",
      "+-----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('binned_score_difference').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|latent_pitch_type| count|\n",
      "+-----------------+------+\n",
      "|              8.0| 25268|\n",
      "|              0.0|620753|\n",
      "|              7.0| 41089|\n",
      "|              1.0|269070|\n",
      "|              4.0|145263|\n",
      "|              3.0|172108|\n",
      "|              2.0|198409|\n",
      "|              6.0| 89226|\n",
      "|              5.0|144449|\n",
      "|              9.0|  6492|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('latent_pitch_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|latent_next_pitch| count|\n",
      "+-----------------+------+\n",
      "|              8.0| 29974|\n",
      "|              0.0|597164|\n",
      "|              7.0| 39667|\n",
      "|              1.0|283170|\n",
      "|              4.0|138905|\n",
      "|              3.0|193926|\n",
      "|              2.0|194296|\n",
      "|              6.0| 92221|\n",
      "|              5.0|136358|\n",
      "|              9.0|  6446|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('latent_next_pitch').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|count_status| count|\n",
      "+------------+------+\n",
      "|           1|233298|\n",
      "|           6| 24340|\n",
      "|           3|237259|\n",
      "|           5|149360|\n",
      "|           9| 50790|\n",
      "|           4| 79288|\n",
      "|           8|218893|\n",
      "|           7|122587|\n",
      "|          10|186938|\n",
      "|          11|112276|\n",
      "|           2|297098|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('count_status').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'outs',\n",
       " 'pfx_x',\n",
       " 'pfx_z',\n",
       " 'pitch_num',\n",
       " 'px',\n",
       " 'pz',\n",
       " 'start_speed',\n",
       " 'sz_bot',\n",
       " 'sz_top',\n",
       " 'x0',\n",
       " 'y0',\n",
       " 'z0',\n",
       " 'batter_id',\n",
       " 'inning',\n",
       " 'p_throws',\n",
       " 'pitcher_id',\n",
       " 'stand',\n",
       " 'top',\n",
       " 'score_difference',\n",
       " 'latent_pitch_type',\n",
       " 'latent_next_pitch',\n",
       " 'count_status',\n",
       " 'base_status',\n",
       " 'binned_score_difference']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('outs', 'pfx_x', 'pfx_z', 'pitch_num', 'px', 'pz', 'start_speed', 'sz_bot', 'sz_top', 'x0', 'y0',\n",
    " 'z0', 'inning', 'p_throws', 'stand', 'latent_pitch_type',\n",
    " 'count_status','base_status', 'binned_score_difference','latent_next_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outs',\n",
       " 'pfx_x',\n",
       " 'pfx_z',\n",
       " 'pitch_num',\n",
       " 'px',\n",
       " 'pz',\n",
       " 'start_speed',\n",
       " 'sz_bot',\n",
       " 'sz_top',\n",
       " 'x0',\n",
       " 'y0',\n",
       " 'z0',\n",
       " 'inning',\n",
       " 'p_throws',\n",
       " 'stand',\n",
       " 'latent_pitch_type',\n",
       " 'count_status',\n",
       " 'base_status',\n",
       " 'binned_score_difference',\n",
       " 'latent_next_pitch']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('binned_score_difference', df.binned_score_difference +5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols =[\"latent_pitch_type\", \"pitch_num\", \"base_status\",\"binned_score_difference\",\n",
    "                                            \"count_status\"],\n",
    "                                 outputCols =[\"latent_pitch_typeH\", \"pitch_numH\", \"base_statusH\",\"binned_score_differenceH\"\n",
    "                                              ,\"count_statusH\"])\n",
    "model = encoder.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(latent_pitch_typeH=SparseVector(9, {0: 1.0})),\n",
       " Row(latent_pitch_typeH=SparseVector(9, {0: 1.0})),\n",
       " Row(latent_pitch_typeH=SparseVector(9, {0: 1.0})),\n",
       " Row(latent_pitch_typeH=SparseVector(9, {7: 1.0})),\n",
       " Row(latent_pitch_typeH=SparseVector(9, {7: 1.0}))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('latent_pitch_typeH').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outs',\n",
       " 'pfx_x',\n",
       " 'pfx_z',\n",
       " 'pitch_num',\n",
       " 'px',\n",
       " 'pz',\n",
       " 'start_speed',\n",
       " 'sz_bot',\n",
       " 'sz_top',\n",
       " 'x0',\n",
       " 'y0',\n",
       " 'z0',\n",
       " 'inning',\n",
       " 'p_throws',\n",
       " 'stand',\n",
       " 'latent_pitch_type',\n",
       " 'count_status',\n",
       " 'base_status',\n",
       " 'binned_score_difference',\n",
       " 'latent_next_pitch',\n",
       " 'count_statusH',\n",
       " 'base_statusH',\n",
       " 'binned_score_differenceH',\n",
       " 'latent_pitch_typeH',\n",
       " 'pitch_numH']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('outs','pfx_x','pfx_z','px','pz','start_speed','sz_bot','sz_top','x0',\n",
    "               'y0','z0','inning','p_throws','stand','latent_pitch_typeH','pitch_numH',\n",
    "               'base_statusH','binned_score_differenceH','count_statusH','latent_next_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(latent_pitch_typeH=SparseVector(9, {0: 1.0}), pitch_numH=SparseVector(14, {1: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), binned_score_differenceH=SparseVector(10, {4: 1.0}), count_statusH=SparseVector(11, {2: 1.0})),\n",
       " Row(latent_pitch_typeH=SparseVector(9, {0: 1.0}), pitch_numH=SparseVector(14, {2: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), binned_score_differenceH=SparseVector(10, {4: 1.0}), count_statusH=SparseVector(11, {5: 1.0})),\n",
       " Row(latent_pitch_typeH=SparseVector(9, {0: 1.0}), pitch_numH=SparseVector(14, {1: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), binned_score_differenceH=SparseVector(10, {}), count_statusH=SparseVector(11, {2: 1.0})),\n",
       " Row(latent_pitch_typeH=SparseVector(9, {7: 1.0}), pitch_numH=SparseVector(14, {2: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), binned_score_differenceH=SparseVector(10, {}), count_statusH=SparseVector(11, {3: 1.0}))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('latent_pitch_typeH','pitch_numH','base_statusH','binned_score_differenceH','count_statusH').take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+\n",
      "|label|            features|  count_statusH|binned_score_differenceH| base_statusH|    pitch_numH|latent_pitch_typeH|\n",
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+\n",
      "|  0.0|[1.0,6.08,9.83,-0...| (11,[2],[1.0])|          (10,[4],[1.0])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[0],[1.0])|\n",
      "|  0.0|[1.0,4.54,12.83,-...| (11,[5],[1.0])|          (10,[4],[1.0])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[0],[1.0])|\n",
      "|  7.0|[0.0,-3.71,9.05,-...| (11,[2],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[0],[1.0])|\n",
      "|  7.0|[0.0,4.87,-6.37,0...| (11,[3],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[7],[1.0])|\n",
      "|  0.0|[0.0,1.64,-4.12,0...| (11,[8],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[3],[1.0])|     (9,[7],[1.0])|\n",
      "|  6.0|[0.0,-2.47,9.54,-...|(11,[10],[1.0])|              (10,[],[])|(7,[0],[1.0])|(14,[4],[1.0])|     (9,[0],[1.0])|\n",
      "|  6.0|[0.0,1.98,6.25,0....|     (11,[],[])|              (10,[],[])|(7,[0],[1.0])|(14,[5],[1.0])|     (9,[6],[1.0])|\n",
      "|  7.0|[2.0,-6.24,7.53,-...| (11,[1],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[2],[1.0])|\n",
      "|  7.0|[2.0,2.25,-7.86,-...| (11,[3],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[7],[1.0])|\n",
      "|  3.0|[2.0,-0.03,-2.33,...| (11,[7],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[3],[1.0])|     (9,[7],[1.0])|\n",
      "|  0.0|[2.0,-7.05,6.16,-...| (11,[9],[1.0])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[4],[1.0])|     (9,[2],[1.0])|\n",
      "|  2.0|[2.0,-3.57,7.96,-...|     (11,[],[])|          (10,[6],[1.0])|(7,[0],[1.0])|(14,[5],[1.0])|     (9,[0],[1.0])|\n",
      "|  6.0|[1.0,-6.56,5.71,0...| (11,[1],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[1],[1.0])|     (9,[3],[1.0])|\n",
      "|  6.0|[1.0,-1.15,10.16,...| (11,[4],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[2],[1.0])|     (9,[6],[1.0])|\n",
      "|  6.0|[1.0,2.3,8.94,-1....| (11,[6],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[3],[1.0])|     (9,[6],[1.0])|\n",
      "|  6.0|[1.0,-0.29,8.41,-...| (11,[9],[1.0])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[4],[1.0])|     (9,[6],[1.0])|\n",
      "|  0.0|[1.0,1.36,8.65,0....|     (11,[],[])|          (10,[1],[1.0])|(7,[4],[1.0])|(14,[5],[1.0])|     (9,[6],[1.0])|\n",
      "|  2.0|[0.0,7.81,-6.61,0...| (11,[2],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(14,[1],[1.0])|     (9,[7],[1.0])|\n",
      "|  0.0|[0.0,-4.02,7.13,-...| (11,[3],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(14,[2],[1.0])|     (9,[3],[1.0])|\n",
      "|  0.0|[0.0,-3.36,12.2,0...| (11,[8],[1.0])|          (10,[2],[1.0])|(7,[0],[1.0])|(14,[3],[1.0])|     (9,[0],[1.0])|\n",
      "+-----+--------------------+---------------+------------------------+-------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-6]), r[-2], r[-3], r[-4], r[-5], r[-6]]).\\\n",
    "           toDF(['label','features', 'count_statusH','binned_score_differenceH','base_statusH', 'pitch_numH',\n",
    "                 'latent_pitch_typeH'])\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data= transData(df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "norm = Normalizer(inputCol='features', outputCol='features_norm', p=1.0)\n",
    "data = norm.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features_norm=DenseVector([0.0056, 0.034, 0.055, -0.003, 0.0151, 0.5239, 0.0104, 0.0214, 0.0121, 0.2796, 0.0344, 0.0056, 0.0, 0.0]))]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('features_norm').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = ['features_norm', 'latent_pitch_typeH','pitch_numH','base_statusH',\n",
    "                                         'binned_score_differenceH','count_statusH'], outputCol = 'features_fin')\n",
    "\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features_fin=SparseVector(65, {0: 0.0056, 1: 0.034, 2: 0.055, 3: -0.003, 4: 0.0151, 5: 0.5239, 6: 0.0104, 7: 0.0214, 8: 0.0121, 9: 0.2796, 10: 0.0344, 11: 0.0056, 14: 1.0, 24: 1.0, 37: 1.0, 48: 1.0, 56: 1.0}))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.select('label', 'features_fin')\n",
    "data.select('features_fin').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = data.filter(data['label'] == 9.0).sample(1165/8285)\\\n",
    ".union(data.filter(data['label'] == 8.0).sample(1165/30932)).union(data.filter(data['label'] == 7.0).sample(1165/50315))\\\n",
    ".union(data.filter(data['label'] == 6.0).sample(1165/109587)).union(data.filter(data['label'] == 5.0).sample(1165/177058))\\\n",
    ".union(data.filter(data['label'] == 4.0).sample(1165/178452)).union(data.filter(data['label'] == 3.0).sample(1165/211755))\\\n",
    ".union(data.filter(data['label'] == 2.0).sample(1165/244465)).union(data.filter(data['label'] == 1.0).sample(1165/330376))\\\n",
    ".union(data.filter(data['label'] == 0.0).sample(1165/763599))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outs',\n",
       " 'pfx_x',\n",
       " 'pfx_z',\n",
       " 'px',\n",
       " 'pz',\n",
       " 'start_speed',\n",
       " 'sz_bot',\n",
       " 'sz_top',\n",
       " 'x0',\n",
       " 'y0',\n",
       " 'z0',\n",
       " 'inning',\n",
       " 'p_throws',\n",
       " 'stand',\n",
       " 'latent_pitch_typeH',\n",
       " 'pitch_numH',\n",
       " 'base_statusH',\n",
       " 'binned_score_differenceH',\n",
       " 'count_statusH',\n",
       " 'latent_next_pitch']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify layers for the neural network: input layer of size 11 (features), two intermediate of size 5 and 4 and output of size 7 (classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currently not working so experimenting with other code\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "layers = [11, 5, 4, 4, 3 , 11]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "FNN = MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\\\n",
    "                                         maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "# Chain indexers and forest in a Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, FNN, labelConverter])\n",
    "# train the model\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "layers = [65, 10, 5, 10]\n",
    "\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=1000, featuresCol = 'features_fin',\n",
    "                                         layers=layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.4239524407592986\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With layers = [23, 20, 15, 6, 11] accuracy = 0.36312009234584086\n",
    "\n",
    "With layers = [23, 20, 15, 11] accuracy = 0.3631949095780308\n",
    "\n",
    "With layers = [22, 30, 15, 11] accuracy = 0.3613826699538746\n",
    "\n",
    "With layers = [68, 10, 5, 11] accuracy = 0.42275469889813827\n",
    "\n",
    "With layers = [65, 10, 5, 10] accuracy = 0.4239524407592986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40100858600575917"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "evaluator.evaluate(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42275469889813827"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "evaluator.evaluate(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ['outs', 'pfx_x', 'pfx_z', 'pitch_num', 'px', 'pz', 'start_speed',\n",
    "        'sz_bot', 'sz_top', 'x0', 'y0','z0', 'inning', 'p_throws', 'stand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "                            inputCols=[c for c in df.columns if c in pred],\n",
    "                            outputCol='features').setHandleInvalid('skip')\n",
    "output = assembler.transform(df)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scaleroutput = scaler.fit(output)\n",
    "scaledoutput = scaleroutput.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=5, inputCol=\"scaledFeatures\", outputCol=\"pcaFeatures\")\n",
    "PC = pca.fit(scaledoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledoutput = PC.transform(scaledoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(outs=1.0, pfx_x=6.08, pfx_z=9.83, px=-0.532, pz=2.702, start_speed=93.7, sz_bot=1.86, sz_top=3.83, x0=2.161, y0=50.0, z0=6.151, inning=1, p_throws=0, stand=0, latent_pitch_typeH=SparseVector(9, {0: 1.0}), pitch_numH=SparseVector(14, {1: 1.0}), base_statusH=SparseVector(7, {0: 1.0}), binned_score_differenceH=SparseVector(10, {4: 1.0}), count_statusH=SparseVector(11, {2: 1.0}), latent_next_pitch=0.0, features=DenseVector([1.0, 6.08, 9.83, -0.532, 2.702, 93.7, 1.86, 3.83, 2.161, 50.0, 6.151, 1.0, 0.0, 0.0]), scaledFeatures=DenseVector([0.0226, 1.1516, 0.9073, -0.5945, 0.4672, 0.8873, 1.8885, 1.7978, 1.6659, 0.0, 0.7366, -1.4967, -1.652, -1.176]), pcaFeatures=DenseVector([-1.7682, -2.8534, -1.4608, -1.8148, -0.4139]))]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledoutput.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [5, 10, 5, 10]\n",
    "\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=1000, featuresCol = 'pcaFeatures', labelCol = 'latent_next_pitch',\n",
    "                                         layers =layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = scaledoutput.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

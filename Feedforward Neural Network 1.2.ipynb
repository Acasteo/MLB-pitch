{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"xor\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data and merge dataset on ab_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches = spark.read.option(\"inferSchema\", \"true\").csv('Data/pitches.csv', header = True)\n",
    "atbats = spark.read.option(\"inferSchema\", \"true\").csv('Data/atbats.csv', header = True).select(\"ab_id\", \"batter_id\", \n",
    "                                                                                               \"inning\", \"p_score\", \n",
    "                                                                                               \"p_throws\", \"pitcher_id\",\n",
    "                                                                                               \"stand\", \"top\")\n",
    "\n",
    "df = pitches.join(atbats, \"ab_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"ax\", \"ay\", \"az\", \"batter_id\", \"break_angle\", \"break_length\", \"break_y\", \"code\", \"event\", \"g_id\", \"o\",\n",
    "            \n",
    "             \"p_throws\", 'nasty',\"pfx_x\", \"pfx_z\", \"px\", \"pz\", \"spin_dir\", \"end_speed\", \"start_speed\"\n",
    "             \n",
    "             \"sz_bot\", \"sz_top\", \"vx0\", \"vy0\", \"vz0\", \"x\", \"x0\", \"y\", \"y0\", \"z\", \"z0\", \"zone\", \"spin_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new variable score_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn(\"score_difference\", df.p_score-df.b_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove low frequency observations (look at pitch_type to decide which ones to remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(\n",
    "    (col('pitch_type') != 'UN') &\n",
    "    (col('pitch_type') != 'EP') &\n",
    "    (col('pitch_type') != 'AB') &\n",
    "    (col('pitch_type') != 'FA') &\n",
    "    (col('pitch_type') != 'IN') &\n",
    "    (col('pitch_type') != 'SC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FO and PO are the same so consolidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.na.replace(['FO'], ['PO'], 'pitch_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new column that is a latent variable based on pitch_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ab_id=2015000044, b_count=0, b_score=0, on_1b=False, on_2b=True, on_3b=False, outs=1, pitch_num=1, pitch_type='FC', s_count=0, start_speed=84.6, sz_bot=1.52, type='B', type_confidence=2.0, inning=5, p_score=3, pitcher_id=425794, stand='L', top=False, score_difference=3, latent_pitch_type=6.0),\n",
       " Row(ab_id=2015000044, b_count=1, b_score=0, on_1b=False, on_2b=True, on_3b=False, outs=1, pitch_num=2, pitch_type='FC', s_count=0, start_speed=88.4, sz_bot=1.52, type='B', type_confidence=2.0, inning=5, p_score=3, pitcher_id=425794, stand='L', top=False, score_difference=3, latent_pitch_type=6.0)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"pitch_type\", outputCol=\"latent_pitch_type\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|latent_pitch_type|  count|\n",
      "+-----------------+-------+\n",
      "|              8.0|  43705|\n",
      "|              0.0|1014880|\n",
      "|              7.0|  66484|\n",
      "|              1.0| 450581|\n",
      "|              4.0| 242506|\n",
      "|              3.0| 292789|\n",
      "|              2.0| 337983|\n",
      "|             10.0|   1438|\n",
      "|              6.0| 149756|\n",
      "|              5.0| 234391|\n",
      "|              9.0|  11260|\n",
      "+-----------------+-------+\n",
      "\n",
      "+----------+-------+\n",
      "|pitch_type|  count|\n",
      "+----------+-------+\n",
      "|        FT| 337983|\n",
      "|        SL| 450581|\n",
      "|        FC| 149756|\n",
      "|        FF|1014880|\n",
      "|        FS|  43705|\n",
      "|        PO|   1438|\n",
      "|        KC|  66484|\n",
      "|        CH| 292789|\n",
      "|        CU| 234391|\n",
      "|        KN|  11260|\n",
      "|        SI| 242506|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"latent_pitch_type\").count().show()\n",
    "df.groupBy(\"pitch_type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## udf_latent_base = udf(lambda z: if)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new column that is latent variable based on balls and strikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_status(b_count, s_count):\n",
    "    if   b_count==0 and s_count==0: return 0\n",
    "    elif b_count==1 and s_count==0: return 1\n",
    "    elif b_count==0 and s_count==1: return 2\n",
    "    elif b_count==1 and s_count==1: return 3\n",
    "    elif b_count==2 and s_count==0: return 4\n",
    "    elif b_count==0 and s_count==2: return 5\n",
    "    elif b_count==3 and s_count==0: return 6\n",
    "    elif b_count==2 and s_count==1: return 7\n",
    "    elif b_count==1 and s_count==2: return 8\n",
    "    elif b_count==3 and s_count==1: return 9\n",
    "    elif b_count==2 and s_count==2: return 10\n",
    "    elif b_count==3 and s_count==2: return 11\n",
    "    \n",
    "udfcount_status = udf(count_status, IntegerType())\n",
    "df = df.withColumn(\"count_status\", udfcount_status(\"b_count\", \"s_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new column that is latent variable based on on_1b, on_2b, and on_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_status(on_1b, on_2b, on_3b):\n",
    "    if   on_1b==0 and on_2b==0 and on_3b==0: return 0\n",
    "    elif on_1b==1 and on_2b==0 and on_3b==0: return 1\n",
    "    elif on_1b==0 and on_2b==1 and on_3b==0: return 2\n",
    "    elif on_1b==0 and on_2b==0 and on_3b==1: return 3\n",
    "    elif on_1b==1 and on_2b==1 and on_3b==0: return 4\n",
    "    elif on_1b==1 and on_2b==0 and on_3b==1: return 5\n",
    "    elif on_1b==0 and on_2b==1 and on_3b==1: return 6\n",
    "    elif on_1b==1 and on_2b==1 and on_3b==1: return 7\n",
    "    \n",
    "udfbase_status = udf(base_status, IntegerType())\n",
    "df = df.withColumn(\"base_status\", udfbase_status(\"on_1b\", \"on_2b\", \"on_3b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new column binning score_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_score(score_difference):\n",
    "    if score_difference<(-4): return (-5)\n",
    "    elif score_difference>(4): return (5)\n",
    "    elif score_difference==(-4): return (-4)\n",
    "    elif score_difference==(-3): return (-3) \n",
    "    elif score_difference==(-2): return (-2)\n",
    "    elif score_difference==(-1): return (-1) \n",
    "    elif score_difference==(0): return (0) \n",
    "    elif score_difference==(1): return (1)\n",
    "    elif score_difference==(2): return (2)\n",
    "    elif score_difference==(3): return (3)\n",
    "    elif score_difference==(4): return (4)\n",
    "udfbin_score = udf(bin_score, IntegerType())\n",
    "df = df.withColumn(\"binned_score_difference\", udfbin_score(\"score_difference\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new column binning pitch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_pitch_num(pitch_num):\n",
    "    if pitch_num>(14): \n",
    "        return (14)\n",
    "    else: \n",
    "        return(pitch_num)\n",
    "udfpitch_num = udf(bin_pitch_num, IntegerType())\n",
    "df = df.withColumn(\"pitch_num\", udfpitch_num(\"pitch_num\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|pitch_num| count|\n",
      "+---------+------+\n",
      "|       12|   409|\n",
      "|        1|735198|\n",
      "|       13|   150|\n",
      "|        6|145005|\n",
      "|        3|539590|\n",
      "|        5|268666|\n",
      "|        9|  8831|\n",
      "|        4|406352|\n",
      "|        8| 23528|\n",
      "|        7| 60001|\n",
      "|       10|  3210|\n",
      "|       11|  1130|\n",
      "|       14|    80|\n",
      "|        2|653623|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"pitch_num\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data to dense vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to dummy encode some of these because it offers useful info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('on_1b', 'on_2b', 'on_3b', 'pitch_type', 'type', 'stand', 'top', 'start_speed', 'sz_bot', 'type_confidence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ab_id', 'int'),\n",
       " ('b_count', 'int'),\n",
       " ('b_score', 'int'),\n",
       " ('outs', 'int'),\n",
       " ('pitch_num', 'int'),\n",
       " ('s_count', 'int'),\n",
       " ('inning', 'int'),\n",
       " ('p_score', 'int'),\n",
       " ('pitcher_id', 'int'),\n",
       " ('score_difference', 'int'),\n",
       " ('latent_pitch_type', 'double'),\n",
       " ('count_status', 'int'),\n",
       " ('base_status', 'int'),\n",
       " ('binned_score_difference', 'int')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"ab_id\",\"b_count\",\"b_score\",\"outs\", 'pitch_num', 's_count', 'inning', 'p_score', 'pitcher_id', 'score_difference',\n",
    "              'count_status', 'base_status', 'binned_score_difference', 'latent_pitch_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ab_id', 'int'),\n",
       " ('b_count', 'int'),\n",
       " ('b_score', 'int'),\n",
       " ('outs', 'int'),\n",
       " ('pitch_num', 'int'),\n",
       " ('s_count', 'int'),\n",
       " ('inning', 'int'),\n",
       " ('p_score', 'int'),\n",
       " ('pitcher_id', 'int'),\n",
       " ('score_difference', 'int'),\n",
       " ('count_status', 'int'),\n",
       " ('base_status', 'int'),\n",
       " ('binned_score_difference', 'int'),\n",
       " ('latent_pitch_type', 'double')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 1, 3, -5, 5, 4, -4, -2, 2, -3, 0]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('binned_score_difference').distinct().rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(subset=[\"count_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------+\n",
      "|binned_score_difference| count|\n",
      "+-----------------------+------+\n",
      "|                     -1|340572|\n",
      "|                      1|344147|\n",
      "|                      3|160611|\n",
      "|                     -5|194611|\n",
      "|                      5|203694|\n",
      "|                      4|112138|\n",
      "|                     -4|106880|\n",
      "|                     -2|232629|\n",
      "|                      2|238861|\n",
      "|                     -3|154079|\n",
      "|                      0|757537|\n",
      "+-----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('binned_score_difference').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  6.0|[2.015000044E9,0....|\n",
      "|  6.0|[2.015000044E9,1....|\n",
      "|  6.0|[2.015000044E9,2....|\n",
      "|  6.0|[2.015000044E9,3....|\n",
      "|  0.0|[2.015000044E9,3....|\n",
      "|  0.0|[2.015000044E9,3....|\n",
      "|  0.0|[2.015000059E9,0....|\n",
      "|  0.0|[2.015000059E9,0....|\n",
      "|  2.0|[2.015000059E9,1....|\n",
      "|  3.0|[2.015000059E9,2....|\n",
      "|  3.0|[2.015000059E9,2....|\n",
      "|  3.0|[2.015000059E9,3....|\n",
      "|  2.0|[2.015000183E9,0....|\n",
      "|  2.0|[2.015000183E9,1....|\n",
      "|  2.0|[2.015000183E9,2....|\n",
      "|  0.0|[2.015000183E9,3....|\n",
      "|  2.0|[2.015000183E9,3....|\n",
      "|  2.0|[2.015000183E9,3....|\n",
      "|  2.0|[2.015000294E9,0....|\n",
      "|  2.0|[2.015000294E9,1....|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).\\\n",
    "           toDF(['label','features'])\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data= transData(df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify layers for the neural network: input layer of size 11 (features), two intermediate of size 5 and 4 and output of size 7 (classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currently not working so experimenting with other code\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "layers = [11, 5, 4, 4, 3 , 11]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "FNN = MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\\\n",
    "                                         maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "# Chain indexers and forest in a Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, FNN, labelConverter])\n",
    "# train the model\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "layers = [13, 5, 4, 11]\n",
    "\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.3570523656068907\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
